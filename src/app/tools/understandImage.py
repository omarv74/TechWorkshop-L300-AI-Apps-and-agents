import os
import base64
from openai import AzureOpenAI
from dotenv import load_dotenv
import numpy as np
import time

# Load environment variables (Azure endpoint, deployment, keys, etc.)
load_dotenv()

# Retrieve credentials from .env file or environment
endpoint = os.getenv("gpt_endpoint")
deployment = os.getenv("gpt_deployment")
api_key = os.getenv("gpt_api_key")

# Initialize Azure OpenAI client for GPT model
client = AzureOpenAI(
    azure_endpoint=endpoint,
    api_key=api_key,
    api_version="2025-01-01-preview",
)

def get_image_description(image_url):
    start_time = time.time()
    """
    Input:
        image_url (str): Full URL to the image file (e.g., JPG, PNG)

    Output:
        summary (str): A Markdown-formatted summary of the image content generated by GPT model
    """

    # Prepare the full chat prompt with system and user messages
    chat_prompt = [
        {
            "role": "system",
            "content": [
                {
                    "type": "text",
                    "text": "You are a helpful assistant that summarizes image content using {image_url} in concise. Respond in Markdown."
                }
            ]
        },
        {"role": "user", "content": image_url}
    ]

    # Call Azure OpenAI chat API
    completion = client.chat.completions.create(
        model=deployment,
        messages=chat_prompt,
        max_completion_tokens=10000,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None,
        stream=False
    )
    end_sum = time.time()
    print(f"summarize_video Execution Time: {end_sum - start_time} seconds")
    # Return summary content
    return completion.choices[0].message.content


# # Example usage
##tested with local path for video: C:\MSFT 2025\Painter Tape.mp4
# image_url =  "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
# summary = get_image_description(image_url)
# print(summary)

